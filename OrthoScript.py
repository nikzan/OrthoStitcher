import cv2
import numpy as np
import glob
from tqdm import tqdm
import os
import argparse


def detect_and_describe(image):
    """
    Детектирует ключевые точки и вычисляет их дескрипторы для входного изображения.

    Использует алгоритм SIFT (Scale-Invariant Feature Transform) для извлечения
    локальных инвариантных признаков, которые устойчивы к изменениям масштаба,
    поворота и освещения.

    Args:
        image (numpy.ndarray): Входное изображение в формате BGR.

    Returns:
        tuple: Кортеж, содержащий:
            - kp (list): Список объектов cv2.KeyPoint, представляющих обнаруженные ключевые точки.
            - des (numpy.ndarray): Массив дескрипторов ключевых точек (float32).
    """
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)  # Преобразование изображения в оттенки серого
    sift = cv2.SIFT_create()  # Инициализация детектора SIFT
    kp, des = sift.detectAndCompute(gray, None)  # Обнаружение ключевых точек и вычисление дескрипторов
    return kp, des


def match_descriptors(des1, des2):
    """
    Сопоставляет дескрипторы между двумя наборами, используя Brute-Force Matcher.

    Применяет критерий отношения расстояний (Lowe's Ratio Test) для фильтрации
    некорректных совпадений, основанный на соотношении двух ближайших совпадений.

    Args:
        des1 (numpy.ndarray): Дескрипторы первого изображения (или текущей панорамы).
        des2 (numpy.ndarray): Дескрипторы второго изображения (для сшивки).

    Returns:
        list: Список объектов cv2.DMatch, представляющих "хорошие" совпадения
              после применения критерия отношения.
    """
    bf = cv2.BFMatcher()  # Инициализация Brute-Force Matcher
    # Поиск k=2 ближайших соседей для каждого дескриптора
    matches = bf.knnMatch(des1, des2, k=2)

    good = []
    for m, n in matches:
        # Применение критерия отношения расстояний Лоу.
        # Совпадение считается "хорошим", если расстояние до ближайшего соседа
        # значительно меньше расстояния до второго ближайшего соседа.
        if m.distance < 0.75 * n.distance:  # Порог отношения
            good.append(m)  # Добавление "хорошего" совпадения в список
    return good


def find_homography(kp1, kp2, matches):
    """
    Вычисляет матрицу гомографии между двумя наборами ключевых точек.

    Использует алгоритм RANSAC (Random Sample Consensus) для повышения устойчивости
    к выбросам (некорректным совпадениям) в наборе данных.

    Args:
        kp1 (list): Список ключевых точек первого изображения.
        kp2 (list): Список ключевых точек второго изображения.
        matches (list): Список объектов cv2.DMatch, представляющих отфильтрованные совпадения.

    Returns:
        numpy.ndarray or None: Матрица гомографии 3x3, если вычисление успешно
                               и доступно достаточно совпадений, иначе None.
    """
    # Для вычисления гомографии требуется минимум 8 точек, но 20 установлены как минимум
    # для надежности RANSAC, чтобы избежать вырожденных решений.
    if len(matches) < 20:
        return None

    # Извлечение координат соответствующих точек из объектов KeyPoint.
    src_pts = np.float32([kp1[m.queryIdx].pt for m in matches]).reshape(-1, 1, 2)
    dst_pts = np.float32([kp2[m.trainIdx].pt for m in matches]).reshape(-1, 1, 2)

    # Вычисление матрицы гомографии с использованием RANSAC.
    # 50.0 - это максимальная допустимая ошибка репроекции (расстояние от точки до её
    # спроецированной точки) для точки, чтобы она считалась инлайером.
    H, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 50.0)
    return H


def blend_images(img1, img2, mask, blend_width=100):
    """
    Выполняет градиентное смешивание двух изображений в области их перекрытия.

    Создает бесшовный переход между изображениями, используя альфа-канал,
    генерируемый на основе расстояния от границ маски. Эта техника помогает
    сгладить видимые швы, вызванные различиями в яркости или цвете.

    Args:
        img1 (numpy.ndarray): Первое изображение (текущая панорама или базовый слой), тип uint8.
        img2 (numpy.ndarray): Второе изображение (трансформированное и подлежащее смешиванию), тип uint8.
        mask (numpy.ndarray): Бинарная маска второго изображения, указывающая его
                              точную область на большом холсте (255 для присутствия, 0 для отсутствия).
        blend_width (int): Ширина области градиентного перехода в пикселях.
                           Большее значение приводит к более плавному, но более широкому смешиванию.

    Returns:
        numpy.ndarray: Смешанное изображение, тип uint8.
    """
    # Преобразование изображений в float32 для точных вычислений с плавающей точкой во время смешивания.
    img1 = img1.astype(np.float32)
    img2 = img2.astype(np.float32)
    mask = mask.astype(np.float32) / 255.0  # Нормализация значений маски до диапазона [0, 1]

    blended = np.zeros_like(img1)  # Инициализация пустого холста для смешанного результата, соответствующего размеру img1.

    # Вычисление карты преобразования расстояний от границ маски.
    # Это создает градиент, где значение каждого пикселя указывает его расстояние до ближайшей границы маски.
    # cv2.DIST_L2 указывает евклидово расстояние. '3' - размер маски для distanceTransform.
    dist = cv2.distanceTransform(mask.astype(np.uint8) * 255, cv2.DIST_L2, 3)

    # Нормализация карты расстояний для получения альфа-канала для смешивания.
    # Значение альфа-канала плавно переходит от 0 до 1 в пределах указанной 'blend_width' от края маски.
    # np.clip гарантирует, что значения альфа-канала остаются в диапазоне [0, 1].
    alpha = np.clip(dist / blend_width, 0, 1)

    # Выполнение градиентного смешивания для каждого цветового канала (BGR).
    # Выходной пиксель представляет собой взвешенную сумму соответствующих пикселей из img1 и img2,
    # с весами (1 - alpha) и alpha соответственно.
    for c in range(3):
        blended[:, :, c] = img1[:, :, c] * (1 - alpha) + img2[:, :, c] * alpha

    # Для областей, где маска второго изображения равна 0 (т.е., img2 отсутствует),
    # убедитесь, что пиксели из первого изображения (img1) сохраняются без смешивания.
    blended[mask == 0] = img1[mask == 0]

    return blended.astype(np.uint8)  # Преобразование конечного смешанного изображения обратно в uint8.


def combine_images(img1, img2, H, blend_width):
    """
    Объединяет два изображения в более широкую панораму, используя гомографическое преобразование
    и градиентное смешивание.

    Эта функция вычисляет необходимый размер холста для размещения обоих изображений
    после преобразования, применяет гомографию ко второму изображению и его маске,
    а затем смешивает его с первым изображением.

    Args:
        img1 (numpy.ndarray): Первое изображение, служащее основой (текущая панорама).
        img2 (numpy.ndarray): Второе изображение, которое будет трансформировано и добавлено к img1.
        H (numpy.ndarray): Матрица гомографии (обратная к той, что была рассчитана find_homography),
                           используемая для преобразования img2 в координатное пространство img1.
        blend_width (int): Ширина в пикселях для области градиентного смешивания.

    Returns:
        numpy.ndarray: Полученное объединенное изображение панорамы (uint8).
    """
    h1, w1 = img1.shape[:2]  # Размеры (высота, ширина) первого изображения
    h2, w2 = img2.shape[:2]  # Размеры второго изображения

    # Определение четырех угловых точек второго изображения.
    corners = np.float32([[0, 0], [0, h2], [w2, h2], [w2, 0]]).reshape(-1, 1, 2)
    # Преобразование этих угловых точек с использованием матрицы гомографии H для нахождения их новых позиций.
    warped_corners = cv2.perspectiveTransform(corners, H)

    # Объединение исходных углов img1 (в [0,0]) с преобразованными углами img2.
    # Это позволяет вычислить ограничивающую рамку всей сшитой панорамы.
    all_corners = np.concatenate((
        warped_corners,
        np.float32([[0, 0], [w1, 0], [0, h1], [w1, h1]]).reshape(-1, 1, 2)
    ), axis=0)

    # Определение минимальных и максимальных координат x и y из всех объединенных углов.
    # Они определяют границы нового, более широкого холста. Вычитание/добавление 1
    # обеспечивает небольшой отступ.
    [x_min, y_min] = np.int32(np.min(all_corners, axis=(0, 1)) - 1)
    [x_max, y_max] = np.int32(np.max(all_corners, axis=(0, 1)) + 1)

    # Создание матрицы сдвига. Эта матрица сдвигает все координаты таким образом, чтобы
    # минимальные x и y (x_min, y_min) стали (0,0) на новом холсте. Это крайне важно
    # для корректного позиционирования изображений без использования отрицательных индексов.
    translation = np.array([[1, 0, -x_min],
                           [0, 1, -y_min],
                           [0, 0, 1]])

    # Создание бинарной маски для второго изображения (полностью белая, 255) и её преобразование
    # с использованием объединенной гомографии (translation * H). Эта маска указывает
    # точные пиксельные местоположения, занимаемые преобразованным вторым изображением на новом холсте.
    mask2 = np.ones((h2, w2), dtype=np.uint8) * 255
    warped_mask2 = cv2.warpPerspective(mask2, translation.dot(H), (x_max - x_min, y_max - y_min),
                                       borderMode=cv2.BORDER_CONSTANT, borderValue=0)

    # Применение морфологической операции эрозии к преобразованной маске. Это создает немного
    # меньшую, буферную область внутри маски. Это помогает в смешивании, гарантируя,
    # что смешивание начнется немного от самого края изображения.
    kernel = np.ones((5, 5), np.uint8)  # Определение ядра 5x5 для операции эрозии.
    morph_mask = cv2.erode(warped_mask2, kernel, iterations=1)  # Выполнение эрозии маски.

    # Преобразование самого второго изображения на новый холст с использованием объединенной гомографии.
    # Области за пределами границ преобразованного изображения будут заполнены нулями (черным цветом).
    warped_img2 = cv2.warpPerspective(img2, translation.dot(H), (x_max - x_min, y_max - y_min),
                                      borderMode=cv2.BORDER_CONSTANT, borderValue=0)

    # Создание конечного холста панорамы, инициализированного нулями (черным цветом).
    panorama = np.zeros((y_max - y_min, x_max - x_min, 3), dtype=np.uint8)

    # Размещение первого изображения (текущей панорамы) на новом холсте панорамы.
    # Его положение определяется рассчитанными смещениями y_min и x_min.
    panorama[-y_min:h1 - y_min, -x_min:w1 - x_min] = img1

    # Смешивание панорамы (содержащей img1) с преобразованным вторым изображением (warped_img2)
    # с использованием морфологической маски для управления процессом смешивания.
    panorama = blend_images(panorama, warped_img2, morph_mask, blend_width)

    return panorama


def stitch_images(images, blend_width):
    """
    Последовательно сшивает список изображений в единую панораму.

    Эта функция обрабатывает изображения одно за другим, принимая текущую составную панораму
    и следующее изображение в последовательности. Она детектирует признаки, сопоставляет их,
    вычисляет необходимое геометрическое преобразование (гомографию), а затем объединяет изображения
    со смешиванием для создания бесшовного результата.

    Args:
        images (list): Список входных изображений, где каждое изображение представляет собой numpy.ndarray.
                       Ожидается, что изображения имеют достаточное перекрытие для успешного
                       сопоставления признаков.
        blend_width (int): Ширина в пикселях, используемая для градиентного смешивания между
                           перекрывающимися областями изображений.

    Returns:
        numpy.ndarray or None: Конечная сшитая панорама в виде numpy.ndarray (uint8),
                               или None, если процесс сшивки не удался (например,
                               из-за недостаточного количества изображений).
    """
    if len(images) < 1:
        return None  # Если входной список пуст, сшивать нечего.

    result = images[0]  # Инициализация панорамы первым изображением в списке.

    # Итерация по оставшимся изображениям, начиная со второго.
    # tqdm используется для отображения полосы прогресса в консоли.
    for i in tqdm(range(1, len(images)), desc="Сшивка изображений"):
        img_current = result  # Текущая составная панорама.
        img_next = images[i]  # Следующее изображение, которое будет добавлено.

        # Шаг 1: Детектирование и описание ключевых точек как для текущей панорамы,
        # так и для следующего изображения.
        kp1, des1 = detect_and_describe(img_current)
        kp2, des2 = detect_and_describe(img_next)

        # Проверка, были ли успешно обнаружены дескрипторы для обоих изображений.
        # Дескрипторы могут быть None, если ключевые точки не найдены на изображении.
        if des1 is None or des2 is None:
            print(f"Предупреждение: Дескрипторы не найдены для изображения {i} или текущей панорамы. Пропускаем это изображение.")
            continue  # Пропустить к следующему изображению, если дескрипторы отсутствуют.

        # Шаг 2: Сопоставление дескрипторов.
        matches = match_descriptors(des1, des2)

        # Шаг 3: Вычисление матрицы гомографии.
        # Гомография (H) описывает перспективное преобразование из img_next в img_current.
        H = find_homography(kp1, kp2, matches)

        if H is None:
            # Если вычисление гомографии не удается (например, недостаточно надежных совпадений),
            # вывести предупреждение и пропустить это изображение.
            print(f"Предупреждение: Вычисление гомографии не удалось для изображения {i + 1}. Не найдено достаточно надежных совпадений. Пропускаем это изображение.")
            continue

        # Для функции combine_images нам нужна гомография, которая преобразует
        # img_next в систему координат общей панорамы.
        # Поскольку H была найдена как преобразование из img_next в img_current,
        # для наложения img_next на img_current (которая уже находится в result), нам нужна H_inv.
        # Обратная гомография (H_inv) корректно позиционирует img_next относительно 'result'.
        H_inv = np.linalg.inv(H)

        # Шаг 4: Объединение изображений.
        # Эта функция обрабатывает изменение размера холста, деформацию изображения и смешивание.
        result = combine_images(img_current, img_next, H_inv, blend_width)

    return result  # Возвращение окончательной сшитой панорамы.


if __name__ == "__main__":
    # 1. Инициализация парсера аргументов командной строки.
    # Это позволяет скрипту принимать различные параметры от пользователя.
    parser = argparse.ArgumentParser(description="Сшивка изображений в панораму")

    # Добавление обязательных аргументов для входной директории и выходного файла.
    parser.add_argument("-i", "--input", required=True, help="Путь к директории с изображениями.")
    parser.add_argument("-o", "--output", required=True, help="Путь к выходному файлу (например, /path/to/pano.jpg).")

    # Добавление необязательных аргументов для ширины смешивания и направления сшивки.
    parser.add_argument("-b", "--blend_width", type=int, default=50,
                        help="Ширина области градиентного смешивания в пикселях (по умолчанию: 50).")
    parser.add_argument("-d", "--direction", choices=["left_to_right", "right_to_left"], default="right_to_left",
                        help="Направление сшивки: 'left_to_right' или 'right_to_left'.")

    # Разбор аргументов, предоставленных пользователем.
    args = parser.parse_args()

    input_path = args.input
    output_file = args.output
    blend_width = args.blend_width
    direction = args.direction

    # 2. Проверка входной директории.
    # Проверка, существует ли предоставленный путь и является ли он директорией.
    if not os.path.isdir(input_path):
        print(f"Ошибка: Директория {input_path} не найдена.")
        exit(1)  # Выход с кодом ошибки, если директория недействительна.

    # 3. Получение отсортированного списка путей к файлам изображений из входной директории.
    # Поддерживаются распространенные форматы изображений (JPG, JPEG, PNG).
    # Параметр 'reverse' в sorted() устанавливается на основе выбранного направления сшивки.
    image_paths = sorted(
        glob.glob(os.path.join(input_path, '*.JPG')) +
        glob.glob(os.path.join(input_path, '*.jpg')) +
        glob.glob(os.path.join(input_path, '*.jpeg')) +
        glob.glob(os.path.join(input_path, '*.png')),
        reverse=(direction == "right_to_left")
    )

    # 4. Загрузка изображений в память.
    images = []
    for img_path in image_paths:
        img = cv2.imread(img_path)
        if img is not None:
            images.append(img)
        else:
            # Вывод предупреждения, если файл изображения не может быть загружен, но продолжение обработки остальных.
            print(f"Ошибка загрузки: {img_path}. Это изображение будет пропущено.")

    # 5. Проверка наличия как минимум 2 изображений для сшивки.
    # Для сшивки требуется минимум два изображения.
    if len(images) < 2:
        print("Для сшивки требуется минимум 2 изображения.")
        exit(1)  # Выход с кодом ошибки, если изображений недостаточно.

    # 6. Выполнение основной логики сшивки изображений.
    # Вызов функции stitch_images с загруженными изображениями и шириной смешивания.
    panorama = stitch_images(images, blend_width)

    # 7. Сохранение окончательной панорамы.
    if panorama is not None:
        cv2.imwrite(output_file, panorama)
        print(f"Панорама сохранена как {output_file}")
    else:
        # Если panorama равна None, это означает, что процесс сшивки не удался (например, совпадения не найдены).
        print("Ошибка при создании панорамы. Возможно, не удалось сопоставить изображения или возникли серьезные проблемы.")